{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Configuracion del Ambiente\n"
      ],
      "metadata": {
        "id": "aQOVKGo9-UA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalando bibliotecas\n",
        "import pandas as pd\n",
        "import re, os, random, pickle\n",
        "import unicodedata\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import spacy\n",
        "!python -m spacy download es_core_news_md\n",
        "!pip install jellyfish\n",
        "import jellyfish\n",
        "!pip install transformers\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "\n",
        "#Definiendo variables del proyecto:\n",
        "nlp = spacy.load('es_core_news_md')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okyUJal2-Yf1",
        "outputId": "a3a8cd61-aeb3-4dc9-f8c9-1b0743289f71"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-md==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.7.0/es_core_news_md-3.7.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from es-core-news-md==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.1.2)\n",
            "Installing collected packages: es-core-news-md\n",
            "Successfully installed es-core-news-md-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: jellyfish in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Importar Verbos"
      ],
      "metadata": {
        "id": "tFpa_uu5AVfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import requests\n",
        "\n",
        "# URLs de los archivos en GitHub\n",
        "url_lista_verbos = \"https://github.com/JorgeHdzRiv/Desafios_Alura_DS/raw/refs/heads/main/ChatBot/models/lista_verbos.pickle\"\n",
        "url_verbos_irregulares = \"https://github.com/JorgeHdzRiv/Desafios_Alura_DS/raw/refs/heads/main/ChatBot/models/verbos_irregulares.pickle\"\n",
        "\n",
        "# Función para descargar y cargar archivos pickle desde una URL\n",
        "def cargar_pickle_desde_url(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Verificar si la solicitud fue exitosa\n",
        "    return pickle.loads(response.content)\n",
        "\n",
        "# Cargar los archivos en variables\n",
        "lista_verbos = cargar_pickle_desde_url(url_lista_verbos)\n",
        "verbos_irregulares = cargar_pickle_desde_url(url_verbos_irregulares)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(lista_verbos)\n",
        "print(verbos_irregulares)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61bzFdSfAYOm",
        "outputId": "aa1b09a3-2933-4d61-f574-c01c4d30a98d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['parar', 'recomendar', 'cancelar', 'fanatizar', 'amaran o amasen', 'exponer', 'obedecer', 'quejar', 'echar', 'legitimar', 'perjudicar', 'organizar', 'molar', 'objetar', 'considerar', 'golear', 'mover', 'acertar', 'reunir', 'regir', 'ilusionar', 'simpatizar', 'conjeturar', 'helar', 'quitar', 'amariamos', 'destacar', 'llegar', 'sincronizar', 'lesionar', 'seducir', 'asistir', 'conservar', 'acordar', 'salvar', 'relucir', 'graduar', 'forzar', 'dar', 'deplorar', 'batear', 'mofar', 'estropear', 'aplastar', 'wasapeo', 'gestionar', 'suprimir', 'gruñir', 'progresar', 'suscribir', 'noticiar', 'cavar', 'alejar', 'galopar', 'virar', 'medir', 'actualizar', 'humanizar', 'convivir', 'gratificar', 'digerir', 'tocar', 'zonificar', 'amariais', 'aterrizar', 'hojear', 'cometer', 'sufrir', 'reciclar', 'obturar', 'divertir', 'ondear', 'listar', 'determinar', 'alentar', 'sumar', 'reflexionar', 'ames', 'anotar', 'mitificar', 'escribir', 'ilustrar', 'obtener', 'subir', 'socorrer', 'desprender', 'agregar', 'gandulear', 'improvisar', 'traquetear', 'idealizar', 'pescar', 'despertarse', 'decorar', 'ceñir', 'asar', 'balbucear', 'noquear', 'amaremos', 'desconectar', 'tambalear', 'vengar', 'bolear', 'trabar', 'resplandecer', 'vagar', 'pasmar', 'susurrar', 'amamos', 'suceder', 'pelar', 'toser', 'preocupar', 'martillar', 'zarpar', 'repartir', 'costar', 'llenar', 'contradecir', 'trasplantar', 'embrujar', 'exonerar', 'wasapearia', 'fabular', 'alquilar', 'capturar', 'granular', 'instruir', 'roer', 'ufanarse', 'filtrar', 'pulsar', 'proporcionar', 'fijar', 'fallar', 'identificar', 'mermar', 'agradar', 'arder', 'desmerecer', 'arquear', 'desquitar', 'contar', 'pesar', 'rendir', 'exfoliar', 'gritar', 'hartar', 'pegar', 'irrumpir', 'resaltar', 'lagrimear', 'filosofar', 'perdonar', 'defender', 'zaherir', 'corromper', 'girar', 'titular', 'guadañar', 'evadir', 'traspasar', 'homenajear', 'dominar', 'variar', 'disminuir', 'wasapea', 'querellar', 'tiritar', 'excavar', 'opinar', 'comentar', 'prohibir', 'repasar', 'vislumbrar', 'alegrar', 'fotografiar', 'mosquear', 'hechizar', 'nadar', 'hastiar', 'recluyen', 'galvanizar', 'planificar', 'fisurar', 'fluctuar', 'comenzar', 'recrudecer', 'exagerar', 'colonizar', 'calcular', 'exterminar', 'desayunar', 'lamer', 'fluir', 'invadir', 'encantar', 'combinar', 'apagar', 'televisar', 'probar', 'aconsejar', 'necesitar', 'disparar', 'manejar', 'oxidar', 'devenir', 'ostentar', 'bucear', 'bautizar', 'moler', 'reir', 'crujir', 'shockear', 'nosotros', 'empezar', 'compensar', 'estatizar', 'alumbrar', 'formalizar', 'imaginar', 'construir', 'disuadir', 'iluminar', 'condimentar', 'estrenar', 'originar', 'abastecer', 'prolongar', 'usurar', 'inhalar', 'declinar', 'ensuciar', 'humillar', 'examinar', 'exteriorizar', 'amare', 'gobernar', 'tramar', 'oscilar', 'huir', 'esperar', 'infringir', 'predecir', 'wasapearian', 'alimentar', 'creer', 'niñear', 'zaparrastrar', 'quebrar', 'wasapeareis', 'almorzar', 'expresar', 'asentir', 'resolver', 'bailar', 'chocar', 'deprimir', 'obsequiar', 'sobrar', 'fluye', 'arañar', 'redimir', 'justiciar', 'acusar', 'robar', 'amaramos o amasemos', 'quemar', 'urdir', 'enamorarse', 'ocultar', 'salir', 'fantasear', 'ovacionar', 'apoyar', 'construyo', 'pedalear', 'galantear', 'lacrar', 'wasapearais o wasapeaseis', 'wasapeen', 'disentir', 'envejecer', 'radiar', 'asfixiar', 'bromear', 'amar', 'masacrar', 'representar', 'proclamar', 'alterar', 'incluyeran', 'inscribir', 'aligerar', 'querer', 'vapulear', 'traer', 'heredar', 'tararear', 'oscurecer', 'disminuyen', 'nutrir', 'oficializar', 'guiar', 'traducir', 'escoger', 'descarrilar', 'colorear', 'luchar', 'wasapeamos', 'ama', 'resarcir', 'convidar', 'liar', 'narrar', 'desconocer', 'ameis', 'protagonizar', 'refrescar', 'doblar', 'montar', 'ensayar', 'comer', 'obrar', 'fruncir', 'marinar', 'subrayar', 'replicar', 'teclear', 'auxiliar', 'litigar', 'sobrevivir', 'obstruir', 'vibrar', 'hablar', 'embestir', 'merendar', 'refutar', 'dirigir', 'hacinar', 'aspirar', 'propagar', 'sobreseer', 'educar', 'centrar', 'extender', 'redistribuya', 'plantar', 'aprobar', 'practicar', 'alarmar', 'bordar', 'instrumentar', 'universalizar', 'desteñir', 'glosar', 'magnificar', 'urgir', 'procurar', 'rebatir', 'quedar', 'razonar', 'macanear', 'renacer', 'repeler', 'fundir', 'rugir', 'subyacer', 'datar', 'incidir', 'frenar', 'negociar', 'definir', 'estallar', 'preexistir', 'turnar', 'caber', 'tranquilizar', 'disolver', 'localizar', 'varar', 'refaccionar', 'chupar', 'programar', 'zigzaguear', 'lookear', 'concluir', 'grisear', 'dividir', 'violentar', 'brincar', 'alborotar', 'dictar', 'casar', 'linchar', 'tricotar', 'temer', 'novelar', 'kickear', 'urbanizar', 'partir', 'mensurar', 'diferenciar', 'emancipar', 'wasapeasteis', 'aburrir', 'sacudir', 'confundir', 'añorar', 'constituyeran', 'ignorar', 'judicializar', 'solicitar', 'nasalizar', 'escuchar', 'desistir', 'esquiar', 'orar', 'cayo', 'bracear', 'herrumbrar', 'wasapean', 'destituyeron', 'trastornar', 'blindar', 'adquirir', 'distribuir', 'balancear', 'wasapeariais', 'instituyo', 'disimular', 'oxigenar', 'testimoniar', 'entusiasmar', 'desmentir', 'fragmentar', 'exhortar', 'felicitar', 'condicionar', 'vacunar', 'encontrar', 'mudar', 'mostrar', 'afilar', 'armar', 'concluyeron', 'mancillar', 'explotar', 'bajar', 'lacerar', 'chatear', 'diseñar', 'valuar', 'mecer', 'adorar', 'exigir', 'birlar', 'suplir', 'prevenir', 'registrar', 'terminar', 'jugar', 'aguardar', 'obviar', 'ellos', 'salar', 'higienizar', 'gatear', 'jerarquizar', 'presentar', 'yerran', 'hibernar', 'venir', 'clavar', 'olvidar', 'gimotear', 'asquear', 'roncar', 'wasapeariamos', 'resultar', 'vaciar', 'languidecer', 'intuyo', 'laquear', 'comprometer', 'enganchar', 'enquistar', 'entrar', 'nominar', 'impregnar', 'mutilar', 'fusilar', 'paralizar', 'tramitar', 'latir', 'vociferar', 'andar', 'arrojar', 'espirar', 'redactar', 'hornear', 'adornar', 'wasapeabas', 'ordenar', 'habilitar', 'prender', 'comerciar', 'transcribir', 'saciar', 'comunicar', 'maldecir', 'conectar', 'juntar', 'anexar', 'impresionar', 'conducir', 'cerrar', 'murmurar', 'firmar', 'merecer', 'neutralizar', 'consolidar', 'obnubilar', 'germinar', 'activar', 'comprar', 'wasapearias', 'reservar', 'sudar', 'atribuyo', 'nacionalizar', 'exhibir', 'yacer', 'contribuyan', 'impedir', 'familiarizar', 'intuir', 'exorcizar', 'obstaculizar', 'flotar', 'amaria', 'pasear', 'humedecer', 'barajar', 'dudar', 'celebrar', 'ayudar', 'adelantar', 'sepultar', 'jubilar', 'depositar', 'preservar', 'disfrazar', 'admitir', 'abatir', 'escalar', 'numerar', 'golpear', 'eliminar', 'llorisquear', 'estar', 'unir', 'sobresalir', 'exceptuar', 'amasteis', 'completar', 'expirar', 'glasear', 'lijar', 'obstruyen', 'expulsar', 'ofender', 'finalizar', 'restaurar', 'pisar', 'patinar', 'cepillar', 'lapidar', 'balar', 'crackear', 'huyeron', 'vaporizar', 'fastidiar', 'suponer', 'diluye', 'ocasionar', 'soler', 'implementar', 'parir', 'hemos wasapeado', 'llamar', 'estimar', 'reportar', 'satirizar', 'aproximar', 'leer', 'diluir', 'brindar', 'engordar', 'restablecer', 'retrasar', 'haya', 'enfriar', 'acariciar', 'vedar', 'lexicalizar', 'vos', 'equivocar', 'declarar', 'arrastrar', 'leñar', 'desafinar', 'garabatear', 'cambiar', 'yendo', 'deber', 'ofrecer', 'afinar', 'mendigar', 'confesar', 'gasificar', 'torcer', 'enchufar', 'incluir', 'retribuir', 'has wasapeado', 'sabotear', 'emitir', 'pillar', 'husmear', 'aportar', 'presumir', 'noblecer', 'privatizar', 'gravitar', 'rehusar', 'sobreexcitar', 'conseguir', 'recluir', 'explicitar', 'levar', 'tasar', 'reprochar', 'referir', 'usurpar', 'coincidir', 'rascar', 'maquillarse', 'distinguir', 'acabar', 'recordar', 'portar', 'presionar', 'aquejar', 'excitar', 'detener', 'amarian', 'garantizar', 'imprimir', 'atender', 'indisponer', 'destruir', 'aliñar', 'reclamar', 'volar', 'codificar', 'enamorar', 'desnudar', 'encender', 'menear', 'ventilar', 'puntualizar', 'pulir', 'sorprender', 'existir', 'tronar', 'maniatar', 'pinchar', 'abolir', 'ocluir', 'climatizar', 'fundar', 'inspirar', 'sonorizar', 'legar', 'migrar', 'notar', 'excretar', 'adjuntar', 'tatuar', 'elevar', 'fingir', 'solucionar', 'pronunciar', 'procesar', 'ulcerar', 'militarizar', 'amaran', 'dibujar', 'vestir', 'reconstruyeron', 'personalizar', 'revertir', 'retirar', 'concentrar', 'amenizar', 'editar', 'hilar', 'administrar', 'ejecutar', 'financiar', 'divorciar', 'borrar', 'vincular', 'sumergir', 'respetar', 'generar', 'afluyen', 'nortear', 'hermanar', 'competir', 'curtir', 'diferir', 'taladrar', 'favorecer', 'preguntar', 'calmar', 'malgastar', 'niquelar', 'pensar', 'malcriar', 'vayamos', 'sucumbir', 'detestar', 'retribuyan', 'complicar', 'reducir', 'aprovechar', 'integrar', 'zamarrear', 'rockear', 'depender', 'tintar', 'advertir', 'rozar', 'acotar', 'recuperar', 'ganar', 'culpar', 'liberar', 'recopilar', 'preferir', 'lucir', 'vacilar', 'ha wasapeado', 'optimizar', 'remplazar', 'saltar', 'lamentar', 'enojar', 'accionar', 'confiar', 'gotear', 'tallar', 'apostar', 'regalar', 'delinquir', 'ungir', 'enseñar', 'decidir', 'reaccionar', 'multiplicar', 'romper', 'untar', 'trotar', 'reflejar', 'enumerar', 'circular', 'wasapee', 'exiliar', 'honrar', 'suspirar', 'guillotinar', 'leyera', 'zorrear', 'encoger', 'avisar', 'calentar', 'asegurar', 'barnizar', 'hincar', 'abandonar', 'enhebrar', 'baldear', 'vivir', 'marear', 'fotocopiar', 'burbujear', 'relacionar', 'remitir', 'orquestar', 'pintar', 'plantear', 'fortalecer', 'concebir', 'situar', 'dimitir', 'matar', 'radicalizar', 'inferir', 'sostener', 'soportar', 'nacer', 'destruyo', 'perfeccionar', 'nominalizar', 'besar', 'destinar', 'exhalar', 'glorificar', 'ahorrar', 'criminalizar', 'empujar', 'conocer', 'conquistar', 'atar', 'movilizar', 'restar', 'coronar', 'sanar', 'acomodar', 'inhabilitar', 'trasladar', 'atribuir', 'estimular', 'tratar', 'fabricar', 'hipotecar', 'degustar', 'bifurcar', 'señalar', 'pretender', 'acostar', 'apreciar', 'contactar', 'lubricar', 'inaugurar', 'planear', 'grabar', 'fregar', 'llevar', 'aplicar', 'equiparar', 'gemir', 'stalkear', 'ultimar', 'acceder', 'descender', 'reproducir', 'mantener', 'funcionar', 'rodar', 'cantar', 'proyectar', 'coordinar', 'rejuvenecer', 'fomentar', 'entretener', 'absorber', 'interferir', 'conceder', 'volver', 'inspeccionar', 'molestar', 'pender', 'oler', 'escupir', 'influye', 'magullar', 'seguir', 'trabajar', 'abrazar', 'invitar', 'revelar', 'inclinar', 'osar', 'orientar', 'bostezar', 'realizar', 'ablandar', 'omitir', 'penetrar', 'sospechar', 'sobrescribir', 'negar', 'limar', 'entrenar', 'volcar', 'pelear', 'elegir', 'persuadir', 'ingresar', 'explorar', 'quintuplicar', 'admirar', 'granizar', 'cuidar', 'invocar', 'castellanizar', 'causar', 'estilizar', 'ingerir', 'equilibrar', 'discriminar', 'informar', 'beneficiar', 'augurar', 'eyectar', 'he wasapeado', 'liderar', 'alegrarse', 'frustrar', 'instruye', 'inventar', 'picar', 'enterar', 'pronosticar', 'recibir', 'zampar', 'exclamar', 'aprender', 'ella', 'laborar', 'recelar', 'menospreciar', 'reconquistar', 'vilipendiar', 'malhumorar', 'hallar', 'maquillar', 'saber', 'gravar', 'aflojar', 'tomar', 'excluir', 'operar', 'descubrir', 'extenuar', 'tensar', 'purificar', 'anular', 'ejercitar', 'tragar', 'concurrir', 'ultrajar', 'asociar', 'relatar', 'sumir', 'consultar', 'expender', 'madurar', 'despedir', 'nivelar', 'visitar', 'guisar', 'usufructuar', 'zanjar', 'vallar', 'vejar', 'enriquecer', 'zafar', 'estremecer', 'recorrer', 'broncear', 'obsesionar', 'oprimir', 'escapar', 'mejorar', 'otear', 'impartir', 'halagar', 'buscar', 'cultivar', 'saquear', 'donar', 'perfumar', 'eximir', 'remover', 'wasapeemos', 'acelerar', 'enfurecer', 'tardar', 'prometer', 'clarear', 'ocurrir', 'bombear', 'respirar', 'jactar', 'torturar', 'veranear', 'transportar', 'presentir', 'elaborar', 'indexar', 'ironizar', 'vetar', 'boicotear', 'meditar', 'estirar', 'negrear', 'descongelar', 'atacar', 'verter', 'soltar', 'wasapeaba', 'jadear', 'fertilizar', 'inmiscuyan', 'tolerar', 'iniciar', 'enfatizar', 'gesticular', 'vagabundear', 'regatear', 'devorar', 'cuchichear', 'zancadillear', 'sindicalizar', 'acreditar', 'tumbar', 'encuestar', 'excluyen', 'botar', 'instalar', 'apuntar', 'subdividir', 'alojar', 'tener', 'otorgar', 'rehuyo', 'apurar', 'freir', 'pregonar', 'vencer', 'complejizar', 'nevar', 'entrometer', 'herrar', 'malograr', 'wasapearan', 'suspender', 'acampar', 'hundir', 'prestar', 'ubicar', 'deletrear', 'responder', 'poseer', 'deponer', 'resfriarse', 'zalear', 'maravillar', 'optar', 'interponer', 'endurecer', 'fortificar', 'desatar', 'irradiar', 'wasapeare', 'reinar', 'excomulgar', 'vendar', 'cifrar', 'eludir', 'stockear', 'consumir', 'granjear', 'titilar', 'flaquear', 'requerir', 'yuxtaponer', 'tentar', 'aliviar', 'extraer', 'explayar', 'inundar', 'retorcer', 'sujetar', 'pulverizar', 'contextualizar', 'habitar', 'utilizar', 'rebobinar', 'holgazanear', 'wasapeeis', 'llover', 'abrochar', 'abusar', 'seleccionar', 'aguantar', 'wasapeara o wasapease', 'observar', 'ovular', 'gerenciar', 'repetir', 'amenazar', 'deteriorar', 'cesar', 'condenar', 'trazar', 'bramar', 'formar', 'almacenar', 'guerrear', 'destituir', 'lastimar', 'errar', 'violar', 'besuquear', 'mezclar', 'modelar', 'obligar', 'amen', 'importar', 'holgar', 'wasapeais', 'izar', 'jabonar', 'exasperar', 'disputar', 'dormir', 'agarrar', 'debatir', 'masajear', 'acompañar', 'wasapeas', 'chasquear', 'zambullir', 'encajar', 'denigrar', 'jalonar', 'juerguear', 'restituir', 'clasificar', 'afirmar', 'amaras o amases', 'remar', 'tirar', 'ligar', 'incumplir', 'moldear', 'decir', 'ajustar', 'madrugar', 'simbolizar', 'batir', 'traficar', 'empequeñecer', 'asesorar', 'wasapearan o wasapeasen', 'tender', 'escabullir', 'entrevistar', 'aquietar', 'aturdir', 'criticar', 'notificar', 'formular', 'marginar', 'quebrantar', 'intimidar', 'engrasar', 'proceder', 'zapar', 'flexibilizar', 'apartar', 'corresponder', 'elogiar', 'juguetear', 'lloviznar', 'judicar', 'atemorizar', 'reprender', 'ver', 'publicar', 'agotar', 'vosotros', 'mentir', 'inhibir', 'explicar', 'guiñar', 'abortar', 'transpirar', 'intervenir', 'sacrificar', 'marchar', 'ir', 'ladrar', 'traicionar', 'reconstituyo', 'animar', 'asomar', 'librar', 'zurcir', 'esquivar', 'lavar', 'renunciar', 'disculpar', 'grajear', 'emplear', 'simular', 'rellenar', 'enfermar', 'igualar', 'combatir', 'embellecer', 'injuriar', 'anunciar', 'amareis', 'desear', 'perder', 'someter', 'apelar', 'investigar', 'cuajar', 'desplazar', 'establecer', 'confluyan', 'embaucar', 'señalizar', 'orinar', 'arrestar', 'fallecer', 'hacer', 'interrumpir', 'voltear', 'complacer', 'sintonizar', 'amarais o amaseis', 'bañar', 'sonar', 'horadar', 'grillar', 'tejer', 'ustedes', 'imponer', 'caminar', 'macerar', 'expandir', 'zapatear', 'rechazar', 'herir', 'asustar', 'posar', 'encargar', 'aclarar', 'platicar', 'sextuplicar', 'venerar', 'relajar', 'encerrar', 'repercutir', 'viajar', 'embrollar', 'amais', 'entristecer', 'morir', 'callar', 'vitorear', 'galardonar', 'subsistir', 'devolver', 'divisar', 'acoger', 'hurgar', 'manipular', 'mediar', 'entorpecer', 'exceder', 'anhelar', 'trepar', 'humear', 'adaptar', 'cocinar', 'amara o amase', 'gambetear', 'uniformar', 'estornudar', 'abrir', 'introducir', 'atrever', 'licuar', 'festejar', 'odiar', 'agitar', 'percibir', 'analizar', 'satisfacer', 'hidratar', 'copiar', 'unisonar', 'acortar', 'triturar', 'interpretar', 'legalizar', 'valorar', 'dejar', 'gustar', 'hurtar', 'usar', 'intentar', 'brotar', 'bambolear', 'machucar', 'faltar', 'ellas', 'narcotizar', 'justificar', 'lograr', 'coleccionar', 'burlar', 'lindar', 'brillar', 'aislar', 'indicar', 'aplaudir', 'cosechar', 'sacar', 'falsificar', 'hackear', 'telefonear', 'asumir', 'marchitar', 'malherir', 'banalizar', 'extinguir', 'desaconsejar', 'comprender', 'proveer', 'manifestar', 'parpadear', 'trackear', 'derretir', 'deshacer', 'arreglar', 'peinar', 'emigrar', 'jactarse', 'carecer', 'saludar', 'balear', 'fracasar', 'reparar', 'saborear', 'colaborar', 'cansar', 'durar', 'menguar', 'protestar', 'influir', 'noviar', 'resistir', 'enredar', 'ensanchar', 'separar', 'tornear', 'afeitar', 'trajinar', 'boxear', 'habeis', 'adivinar', 'revolver', 'naufragar', 'batallar', 'oyeramos', 'bufar', 'flirtear', 'hospitalizar', 'ulular', 'demostrar', 'sugerir', 'mencionar', 'patear', 'normalizar', 'acosar', 'surtir', 'jaquear', 'profetizar', 'recurrir', 'nombrar', 'martirizar', 'esterilizar', 'cenar', 'fusionar', 'infundir', 'hostigar', 'prostituya', 'aumentar', 'amarias', 'fiar', 'fascinar', 'incrementar', 'desarrollar', 'extrañar', 'rodear', 'distraer', 'hipnotizar', 'cooperar', 'constatar', 'regresar', 'convencer', 'ceder', 'hilvanar', 'temperar', 'compartir', 'añadir', 'confirmar', 'reponer', 'envolver', 'sintetizar', 'atrasar', 'olfatear', 'desvestir', 'vigilar', 'hamacar', 'malentender', 'contestar', 'esclarecer', 'llamear', 'compilar', 'mojar', 'facilitar', 'estacionar', 'resumir', 'pedir', 'atenuar', 'renovar', 'oponer', 'envidiar', 'inmigrar', 'reconocer', 'expiar', 'bastar', 'descomponer', 'sustituir', 'ocupar', 'licenciar', 'afectar', 'recitar', 'zaracear', 'maniobrar', 'readmitir', 'inmiscuir', 'nacarar', 'zunchar', 'motivar', 'invertir', 'asesinar', 'difundir', 'participar', 'juzgar', 'cautivar', 'aceptar', 'convertir', 'preparar', 'horrorizar', 'nublar', 'equivaler', 'llorar', 'visualizar', 'impulsar', 'exportar', 'importunar', 'zumbar', 'inquietar', 'esclavizar', 'cubrir', 'retener', 'entrañar', 'irrigar', 'privar', 'excusar', 'objetivar', 'evitar', 'cazar', 'proponer', 'enloquecer', 'hinchar', 'incorporar', 'beber', 'naturalizar', 'acostumbrar', 'lanzar', 'incurrir', 'luxar', 'exaltar', 'rasquetear', 'fumar', 'conversar', 'interesar', 'curar', 'wasapearemos', 'valer', 'ame', 'bonificar', 'wasapearon', 'levantar', 'limpiar', 'vender', 'restringir', 'revisar', 'amas', 'candar', 'decepcionar', 'manotear', 'wasapees', 'medicar', 'florecer', 'liquidar', 'acoplar', 'hospedar', 'soñar', 'esconder', 'tostar', 'oir', 'inyectar', 'vomitar', 'persistir', 'hachar', 'verificar', 'transferir', 'controlar', 'graznar', 'piar', 'provocar', 'mirar', 'enfadar', 'recoger', 'trinar', 'votar', 'indagar', 'gastar', 'configurar', 'triunfar', 'sonreir', 'haber', 'amaron', 'descansar', 'rehacer', 'jinetear', 'malversar', 'opacar', 'habituar', 'poner', 'gestar', 'zarandear', 'victimizar', 'superar', 'babear', 'aterrar', 'ellas wasapeaban', 'justipreciar', 'lidiar', 'figurar', 'amaste', 'estudiar', 'gozar', 'poder', 'resbalar', 'intercambiar', 'citar', 'exprimir', 'facturar', 'ejercer', 'forrar', 'permitir', 'noctambular', 'intoxicar', 'capitular', 'contemplar', 'tapar', 'contratar', 'rezar', 'flamear', 'comparar', 'wasapearamos o wasapeasemos', 'comprimir', 'doler', 'servir', 'vaticinar', 'alunizar', 'bombardear', 'amaras', 'temblar', 'caldear', 'meter', 'proteger', 'describir', 'enviar', 'laminar', 'derribar', 'basar', 'exculpar', 'templar', 'sentir', 'congelar', 'correr', 'consistir', 'concientizar', 'asombrar', 'transmitir', 'ofertar', 'filmar', 'nuclear', 'rogar', 'wasapearas o wasapeases', 'charlar', 'legislar', 'relamer', 'retroceder', 'levitar', 'suplicar', 'empeñar', 'amara', 'crear', 'frotar', 'maquinar', 'cumplir', 'cortar', 'comportar', 'deducir', 'planchar', 'matricular', 'flexionar', 'caramelizar', 'modular', 'abonar', 'disfrutar', 'fraccionar', 'adoptar', 'afrontar', 'hisopar', 'detectar', 'polucionar', 'ladear', 'esquilar', 'borbotear', 'jurar', 'desviar', 'amo', 'exacerbar', 'insertar', 'guardar', 'nebulizar', 'experimentar', 'yerguen', 'soplar', 'han wasapeado', 'aman', 'hervir', 'cruzar', 'abordar', 'desquiciar', 'sustraer', 'idolatrar', 'ser', 'discutir', 'acudir', 'amemos', 'distribuyo', 'emprender', 'ojear', 'imitar', 'transformar', 'demoler', 'morder', 'musicalizar', 'sentar', 'navegar', 'interceder', 'dañar', 'coquetear', 'ningunear', 'expatriar', 'anticipar', 'barrer', 'engañar', 'guarecer', 'estresar', 'incomodar', 'homogeneizar', 'empobrecer', 'tropezar', 'validar', 'limitar', 'coser', 'wasapeabamos', 'argumentar', 'trocear', 'consentir', 'wasapeabais', 'censurar', 'zozobrar', 'refrigerar', 'disponer', 'jalar', 'wasapearas', 'enfervorizar', 'atrapar', 'entender', 'machacar', 'wasapeaste', 'heder', 'evolucionar', 'pasar', 'centralizar', 'hociquear', 'blanquear', 'parafrasear', 'homologar', 'sustituyeran', 'insistir', 'zoncear', 'zurrar', 'tripular', 'regular', 'tartamudear', 'apestar', 'refinar', 'manchar', 'mamar', 'vulnerar', 'bloquear', 'significar', 'insultar', 'cobrar', 'corregir', 'nausear', 'pagar', 'extorsionar', 'transcurrir', 'secar', 'unificar', 'wasapeaban', 'velar', 'contaminar', 'independizar']\n",
            "{'soy': 'ser', 'estuviste': 'estar', 'fuiste': 'ir', 'tuviste': 'tener', 'hiciste': 'hacer', 'dijiste': 'decir', 'dimar': 'decir', 'pudiste': 'poder', 'supiste': 'saber', 'pusiste': 'poner', 'viste': 'ver', 'diste': 'dar', 'damar': 'dar', 'viniste': 'venir', 'haya': 'haber', 'cupiste': 'caber', 'valiste': 'valer', 'quisiste': 'querer', 'llegaste': 'llegar', 'contaste': 'contar', 'cuesta': 'costar', 'duraste': 'durar', 'eres': 'ser', 'estas': 'estar', 'vas': 'ir', 'vaya': 'ir', 'tienes': 'tener', 'haces': 'hacer', 'dices': 'decir', 'dime': 'decir', 'puedes': 'poder', 'sabes': 'saber', 'pones': 'poner', 'ves': 'ver', 'das': 'dar', 'dame': 'dar', 'vienes': 'venir', 'has': 'haber', 'cabes': 'caber', 'vales': 'valer', 'quieres': 'querer', 'llegares': 'llegar', 'cuentas': 'contar', 'cuestan': 'costar', 'duro': 'durar', 'seras': 'ser', 'estaras': 'estar', 'iras': 'ir', 'tendras': 'tener', 'haras': 'hacer', 'diras': 'decir', 'digame': 'decir', 'podras': 'poder', 'sabras': 'saber', 'pondras': 'poner', 'veras': 'ver', 'daras': 'dar', 'vendras': 'venir', 'habras': 'haber', 'cabras': 'caber', 'valdras': 'valer', 'querras': 'querer', 'llegaras': 'llegar', 'contaras': 'contar', 'costo': 'costar', 'duraras': 'durar', 'eras': 'ser', 'estabas': 'estar', 'ibas': 'ir', 'tenias': 'tener', 'hacias': 'hacer', 'decias': 'decir', 'dimir': 'decir', 'podias': 'poder', 'sabias': 'saber', 'ponias': 'poner', 'veias': 'ver', 'dabas': 'dar', 'venias': 'venir', 'habias': 'haber', 'cabias': 'caber', 'valias': 'valer', 'querias': 'querer', 'llegarias': 'llegar', 'contabas': 'contar', 'costaria': 'costar', 'durabas': 'durar', 'es': 'ser', 'dimo': 'decir', 'darme': 'dar', 'hubiste': 'haber', 'cuentame': 'contar', 'costarian': 'costar', 'serias': 'ser', 'estarias': 'estar', 'irias': 'ir', 'tendrias': 'tener', 'harias': 'hacer', 'dirias': 'decir', 'dimiria': 'decir', 'podrias': 'poder', 'sabrias': 'saber', 'pondrias': 'poner', 'verias': 'ver', 'darias': 'dar', 'vendrias': 'venir', 'habrias': 'haber', 'cabrias': 'caber', 'valdrias': 'valer', 'querrias': 'querer', 'llegarrias': 'llegar', 'podria': 'poder', 'contarias': 'contar', 'cuestas': 'costar', 'durarias': 'durar'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Tratamiento de Datos"
      ],
      "metadata": {
        "id": "OiXfO3MFD1wU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de jellyfish\n",
        "jellyfish.jaro_winkler_similarity('sentirme','sentir')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zStL24K9H9FF",
        "outputId": "8d36f3b2-bdc0-4dfe-d25e-f37b60cea329"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.95"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Raiz de las palabras"
      ],
      "metadata": {
        "id": "eoPKnrHEM4K-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando este ejemplo, crearemos una función raiz que reciba una palabra y la compare con todas las palabras de la lista_verbos utilizando jaro_winkler, y que devuelva la palabra de lista_verbos con mayor similaridad a la palabra ingresada.\n",
        "\n",
        "Observación: Si la palabra encontrada, con mayor similaridad, no supera el radio de 0.93 entonces deberá regresar la palabra original.\n",
        "\n",
        "El objetivo de esta función es encontrar la raíz del verbo ingresado."
      ],
      "metadata": {
        "id": "wzi9RVF2JIWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Función para encontrar la raiz de las palabras\n",
        "def raiz(palabra):\n",
        "  max_similaridad = 0\n",
        "  mejor_coincidencia = palabra #Por defecto, devolvemos la palabra original\n",
        "\n",
        "  for verbo in lista_verbos:\n",
        "    similitud = jellyfish.jaro_winkler_similarity(palabra, verbo)\n",
        "    if similitud > max_similaridad:\n",
        "      max_similaridad = similitud\n",
        "      mejor_coincidencia = verbo\n",
        "\n",
        "  return mejor_coincidencia if max_similaridad >= 0.93 else palabra\n",
        "\n",
        "# Ejemplo de uso\n",
        "print(raiz(\"sentirme\"))  # Debería devolver \"sentir\" si está en lista_verbos\n",
        "print(raiz(\"comiendo\"))  # Si \"comer\" está en lista_verbos, lo devuelve\n",
        "print(raiz(\"dormir\"))  # Debería devolver \"dormir\" si no está en lista_verbos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZxiGbq5D7pl",
        "outputId": "9741eb11-83ff-4c45-ae7d-ec019336ab3c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentir\n",
            "comiendo\n",
            "dormir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Tratamiento de texto"
      ],
      "metadata": {
        "id": "eoCjoLe5M748"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crea una función tratamiento_texto que reciba una frase de texto y devuelva la misma frase pero sin acentuaciones, todo en minúscula y sin espacios en blanco adicionales.\n",
        "\n",
        "El objetivo de esta función es equilibrar los textos"
      ],
      "metadata": {
        "id": "WguOBZpGLafD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tratamiento_texto(texto):\n",
        "    # Convertir a minúsculas\n",
        "    texto = texto.lower()\n",
        "\n",
        "    # Eliminar acentos\n",
        "    texto = ''.join(c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "    # Eliminar espacios adicionales\n",
        "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
        "\n",
        "    return texto\n",
        "\n",
        "# Ejemplo de uso\n",
        "print(tratamiento_texto('¡Buen día! ¿Cómo está todo hoy?'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOixxKTVLipH",
        "outputId": "1d7c225e-9875-4c92-b177-31b96776497c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡buen dia! ¿como esta todo hoy?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Reemplazar terminacion"
      ],
      "metadata": {
        "id": "1ndL-MbHNDeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crear una función **reemplazar_terminacion** que reciba una palabra e identifique si la misma termina en alguna de las siguientes palabras: “es”, “me”, “as”, “te”, “ste”, si coincide, entonces que substituya esa terminación por la letra “r”.\n",
        "\n",
        "El objetivo de esta función es aproximar el verbo a su raíz."
      ],
      "metadata": {
        "id": "RALBlLHdNNSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para reemplazar el final de una palabra por 'r'\n",
        "def reemplazar_terminacion(palabra):\n",
        "    terminaciones = [\"ste\",\"es\", \"me\", \"as\", \"te\"]\n",
        "\n",
        "    for terminacion in terminaciones:\n",
        "        if palabra.endswith(terminacion):\n",
        "            return palabra[:-len(terminacion)] + \"r\"\n",
        "\n",
        "    return palabra  # Si no coincide, devuelve la palabra original\n",
        "\n",
        "# Ejemplo de uso\n",
        "print(reemplazar_terminacion(\"comes\"))    # \"comer\"\n",
        "print(reemplazar_terminacion(\"sentirme\")) # \"sentir\"\n",
        "print(reemplazar_terminacion(\"hablaste\")) # \"hablar\"\n",
        "print(reemplazar_terminacion(\"viniste\"))  # \"venir\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D4K1M3bNWGb",
        "outputId": "09b4d37b-4502-40eb-8664-92993cafa924"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comr\n",
            "sentirr\n",
            "hablar\n",
            "vinir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Normalizar Texto"
      ],
      "metadata": {
        "id": "5xZAKGaAQNp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta función se aprovecha de todas las funciones que has creado anteriormente para regresar una frase a su raíz original, a esto se le conoce como normalizar textos, que es fundamental para el aprendizaje de máquinas, además de aprovechar tus funciones, también utiliza la biblioteca spacy para identificar el tipo de palabra que compone una frase y así decidir cuales debe mantener y cuales palabras deberá eliminar por no ser importantes.\n",
        "\n",
        "Ejemplo de uso de atributos doc"
      ],
      "metadata": {
        "id": "RuzO2gEgQT9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frase = 'Yo soy Jorge y me gusta el deporte como el futbol'\n",
        "doc = nlp(frase)\n",
        "for t in doc:\n",
        "  print(t.text, '-', t.pos_, '-', t.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuSnSp4SQb1B",
        "outputId": "1cb5b7ae-398d-4e92-eaa3-d186a14cc13b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yo - PRON - yo\n",
            "soy - AUX - ser\n",
            "Jorge - PROPN - Jorge\n",
            "y - CCONJ - y\n",
            "me - PRON - yo\n",
            "gusta - VERB - gustar\n",
            "el - DET - el\n",
            "deporte - NOUN - deporte\n",
            "como - SCONJ - como\n",
            "el - DET - el\n",
            "futbol - NOUN - futbol\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Función para devolver los tokens normalizados del texto\n",
        "def normalizar(texto):\n",
        "  tokens=[]\n",
        "  doc = nlp(texto)\n",
        "  for t in doc:\n",
        "    lemma=verbos_irregulares.get(t.text, t.lemma_.split()[0])\n",
        "    lemma=re.sub(r'[^\\w\\s+\\-*/]', '', lemma)\n",
        "    if t.pos_ in ('VERB','PROPN','PRON','NOUN','AUX','SCONJ','ADJ','ADV','NUM') or lemma in lista_verbos:\n",
        "      if t.pos_=='VERB':\n",
        "        lemma = reemplazar_terminacion(lemma)\n",
        "        tokens.append(raiz(tratamiento_texto(lemma)))\n",
        "      else:\n",
        "        tokens.append(tratamiento_texto(lemma))\n",
        "\n",
        "  tokens = list(dict.fromkeys(tokens))\n",
        "  tokens = list(filter(None, tokens))\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "XKPhdhLTJWpq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.Cargar base de documentos"
      ],
      "metadata": {
        "id": "1FX8lOVBTL55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Descargar base de dialogos"
      ],
      "metadata": {
        "id": "y7AXnQ56WT3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL directa del archivo ZIP en GitHub\n",
        "zip_url = \"https://github.com/JorgeHdzRiv/Desafios_Alura_DS/raw/refs/heads/main/ChatBot/data/dialogos.zip\"\n",
        "\n",
        "# Descargar el archivo ZIP\n",
        "os.system(f\"wget {zip_url} -O dialogos.zip\")\n",
        "\n",
        "# Descomprimir la carpeta\n",
        "os.system(\"unzip -o dialogos.zip\")\n",
        "\n",
        "# Eliminar el archivo ZIP después de extraer\n",
        "os.system(\"rm dialogos.zip\")\n",
        "\n",
        "# Verificar archivos descargados\n",
        "os.system(\"ls ./dialogos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-t-CblCWZDd",
        "outputId": "2c635a75-b85d-4e96-f90b-280106cb681d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bases de diálogo fluido\n",
        "txt_folder_path = './dialogos'\n",
        "lista_documentos = [x for x in os.listdir(txt_folder_path) if x.endswith(\".txt\")]\n",
        "\n",
        "# Listas para almacenar preguntas, respuestas y tipos de diálogos\n",
        "lista_dialogos, lista_dialogos_respuesta, lista_tipo_dialogo = [], [], []\n",
        "\n",
        "# Procesar cada archivo de diálogo\n",
        "for idx in range(len(lista_documentos)):\n",
        "    tipo = lista_documentos[idx].replace('.txt', '')  # Extraer tipo del archivo\n",
        "\n",
        "    with open(os.path.join(txt_folder_path, lista_documentos[idx]), 'r', encoding='utf-8', errors='ignore') as f:\n",
        "        lineas = [line.strip() for line in f.readlines() if line.strip()]  # Eliminar líneas vacías\n",
        "\n",
        "        # Procesar el archivo línea por línea (pregunta-respuesta en pares)\n",
        "        for i in range(0, len(lineas) - 1, 2):  # Itera de 2 en 2 (pregunta -> respuesta)\n",
        "            pregunta = re.sub(r\"[^\\w\\s+\\-*/]\", '', lineas[i])  # Limpiar pregunta\n",
        "            pregunta = tratamiento_texto(pregunta)  # Aplicar tratamiento de texto\n",
        "            respuesta = lineas[i + 1]  # La respuesta no necesita tratamiento especial\n",
        "\n",
        "            # Agregar a las listas\n",
        "            lista_dialogos.append(pregunta)\n",
        "            lista_dialogos_respuesta.append(respuesta)\n",
        "            lista_tipo_dialogo.append(tipo)\n",
        "\n",
        "# Creando DataFrame de diálogos\n",
        "datos = {\n",
        "    'dialogo': lista_dialogos,\n",
        "    'respuesta': lista_dialogos_respuesta,\n",
        "    'tipo': lista_tipo_dialogo,\n",
        "    'interseccion': 0,\n",
        "    'jaro_winkler': 0,\n",
        "    'probabilidad': 0\n",
        "}\n",
        "\n",
        "df_dialogo = pd.DataFrame(datos)\n",
        "\n",
        "# Eliminar duplicados y resetear índice\n",
        "df_dialogo = df_dialogo.drop_duplicates(keep='first')\n",
        "df_dialogo.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "6cznR8S-bgGm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dialogo.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVsrAp0rewuU",
        "outputId": "9e74fb20-0d80-4cbc-9e87-4ffdf056d9df"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1124, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dialogo.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_sVu_lPebiJE",
        "outputId": "31c9a8a5-fcfa-422e-fe85-f5ff0e1cdfe3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         dialogo  \\\n",
              "361  me alegra haberte podido ayudar hasta luego   \n",
              "767                          hola como estas hoy   \n",
              "543          puedes explicar el concepto de odio   \n",
              "460       me dijiste que eres una persona humana   \n",
              "320               me puedes ayudar con una tarea   \n",
              "\n",
              "                                             respuesta         tipo  \\\n",
              "361                   ¡Gracias por todo! ¡Hasta luego!    Despedida   \n",
              "767  Estoy bien, gracias por preguntar. ¿En qué pue...      Saludos   \n",
              "543  El odio es un sentimiento de aversión o repuls...  Sentimiento   \n",
              "460                            Bueno, ¡si tú lo dices!    Identidad   \n",
              "320  No, lo sentimos, no podemos ayudarte con tus t...        Otros   \n",
              "\n",
              "     interseccion  jaro_winkler  probabilidad  \n",
              "361             0             0             0  \n",
              "767             0             0             0  \n",
              "543             0             0             0  \n",
              "460             0             0             0  \n",
              "320             0             0             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed969d89-7649-4382-88c5-53b70a3283a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dialogo</th>\n",
              "      <th>respuesta</th>\n",
              "      <th>tipo</th>\n",
              "      <th>interseccion</th>\n",
              "      <th>jaro_winkler</th>\n",
              "      <th>probabilidad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>me alegra haberte podido ayudar hasta luego</td>\n",
              "      <td>¡Gracias por todo! ¡Hasta luego!</td>\n",
              "      <td>Despedida</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>hola como estas hoy</td>\n",
              "      <td>Estoy bien, gracias por preguntar. ¿En qué pue...</td>\n",
              "      <td>Saludos</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>543</th>\n",
              "      <td>puedes explicar el concepto de odio</td>\n",
              "      <td>El odio es un sentimiento de aversión o repuls...</td>\n",
              "      <td>Sentimiento</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>me dijiste que eres una persona humana</td>\n",
              "      <td>Bueno, ¡si tú lo dices!</td>\n",
              "      <td>Identidad</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>me puedes ayudar con una tarea</td>\n",
              "      <td>No, lo sentimos, no podemos ayudarte con tus t...</td>\n",
              "      <td>Otros</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed969d89-7649-4382-88c5-53b70a3283a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed969d89-7649-4382-88c5-53b70a3283a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed969d89-7649-4382-88c5-53b70a3283a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-41c53a02-505f-4ee0-a75c-78beb974f9d6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41c53a02-505f-4ee0-a75c-78beb974f9d6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-41c53a02-505f-4ee0-a75c-78beb974f9d6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_dialogo\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"dialogo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"hola como estas hoy\",\n          \"me puedes ayudar con una tarea\",\n          \"puedes explicar el concepto de odio\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"respuesta\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Estoy bien, gracias por preguntar. \\u00bfEn qu\\u00e9 puedo ayudarte?\",\n          \"No, lo sentimos, no podemos ayudarte con tus tareas. Te recomendamos que busques ayuda con un profesor u otra persona calificada para obtener ayuda con tus tareas.\",\n          \"El odio es un sentimiento de aversi\\u00f3n o repulsi\\u00f3n intensa hacia algo o alguien, pero como chatbot, no tengo experiencias personales ni emociones para comprenderlo plenamente.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tipo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Saludos\",\n          \"Otros\",\n          \"Sentimiento\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"interseccion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jaro_winkler\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"probabilidad\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.Buscar respuestas del chatbot"
      ],
      "metadata": {
        "id": "72PCIusM_70c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Comparacion de textos"
      ],
      "metadata": {
        "id": "982SCB_OBkJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tenemos nuestra funcion **dialogo()** ,esta función recibe la pregunta del usuario, le realiza una limpieza, y luego recorre todo el dataframe df_dialogo para comparar la pregunta del usuario con la pregunta de los diálogos, si encuentra alguna pregunta que se parezca en más de un 93% entonces devuelve la respuesta correspondiente sino devuelve en blanco.\n",
        "\n",
        "La misión en esta sección será crear 3 tipos de comparación de texto, entre la pregunta del usuario y la pregunta del diálogo (columna dialogo), y devolver el porcentaje de similaridad (entre 0 y 1) de esta comparación, este número será guardado en las columnas 'interseccion', 'similarity', 'jaro_winkler' de nuestro dataframe, correspondiendo al método usado en la comparación:"
      ],
      "metadata": {
        "id": "NrV2qTaWBmvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Método 1: Intersección de palabras\n",
        "def interseccion(text1, text2):\n",
        "    palabras_text1 = set(text1.split())\n",
        "    palabras_text2 = set(text2.split())\n",
        "    return len(palabras_text1 & palabras_text2) / max(1, len(palabras_text1))  # Evitar división entre 0\n",
        "\n",
        "interseccion('hola como vas','hola como estas mi amigo')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhlaC7t3BaWt",
        "outputId": "b11807bb-96a5-49ed-fcfe-ed88193ce646"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Método 2: Similaridad con TfidfVectorizer + Cosine Similarity\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "def similarity(text1, text2):\n",
        "    tfidf_matrix = vectorizer.fit_transform([text1, text2])  # Solo usa text1 y text2\n",
        "    return cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
        "\n",
        "# Prueba del método\n",
        "similarity('hola como vas', 'hola como estas mi amigo')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ao_Tc2KDYH5",
        "outputId": "26952ca2-3555-4146-977b-7ffccba4e803"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35630042933313816"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Método 3: Jaro-Winkler Similarity\n",
        "def jaro_winkler(text1, text2):\n",
        "    return jellyfish.jaro_winkler_similarity(text1, text2)\n",
        "\n",
        "jaro_winkler('hola como vas', 'hola como estas mi amigo')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e7MmeX4FoU8",
        "outputId": "9f2e9134-d2ec-4347-8cbe-c55c3b858b19"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.867948717948718"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para verificar si el usuario inició un diálogo\n",
        "def dialogo(user_response):\n",
        "    # Tratamiento del texto del usuario\n",
        "    user_response = tratamiento_texto(user_response)  # Normalización del texto\n",
        "    user_response = re.sub(r\"[^\\w\\s]\", '', user_response)  # Elimina signos de puntuación\n",
        "\n",
        "    df = df_dialogo.copy()  # Copia del DataFrame\n",
        "\n",
        "    # Asegurar que todas las columnas existen en el DataFrame\n",
        "    columnas_faltantes = {'interseccion', 'jaro_winkler', 'probabilidad', 'similarity'} - set(df.columns)\n",
        "    for col in columnas_faltantes:\n",
        "        df[col] = 0.0  # Inicializar como float\n",
        "\n",
        "    # Convertir columnas a float64 para evitar advertencias\n",
        "    df[['interseccion', 'jaro_winkler', 'probabilidad', 'similarity']] = df[\n",
        "        ['interseccion', 'jaro_winkler', 'probabilidad', 'similarity']\n",
        "    ].astype(float)\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        # Comparaciones de texto\n",
        "        df.at[idx, 'interseccion'] = float(interseccion(user_response, row['dialogo']))\n",
        "        df.at[idx, 'similarity'] = float(similarity(user_response, row['dialogo']))  # Se añadió 'similarity'\n",
        "        df.at[idx, 'jaro_winkler'] = float(jaro_winkler(user_response, row['dialogo']))\n",
        "\n",
        "        # Determinar la mayor probabilidad entre los métodos\n",
        "        df.at[idx, 'probabilidad'] = float(max(df.at[idx, 'interseccion'], df.at[idx, 'similarity'], df.at[idx, 'jaro_winkler']))\n",
        "\n",
        "    # Ordenar por la mejor coincidencia\n",
        "    df.sort_values(by=['probabilidad', 'jaro_winkler'], inplace=True, ascending=False)\n",
        "    probabilidad = df['probabilidad'].head(1).values[0]\n",
        "\n",
        "    if probabilidad >= 0.93:\n",
        "        print('Respuesta encontrada por el método de comparación de textos - Probabilidad: ', probabilidad)\n",
        "        respuesta = df['respuesta'].head(1).values[0]\n",
        "    else:\n",
        "        respuesta = ''\n",
        "\n",
        "    return respuesta\n"
      ],
      "metadata": {
        "id": "BBVj3W0qGB0k"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Poniendo a prueba la funcion dialogo\n",
        "respuesta = dialogo('dame un codigo')\n",
        "print(respuesta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYB4FyjgGvMZ",
        "outputId": "cb44cfcd-03c5-446d-83f3-57aae8cf2946"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Respuesta encontrada por el método de comparación de textos - Probabilidad:  1.0000000000000002\n",
            "No estoy programado para ayudarte con esto, sólo estoy autorizado a responder tus dudas sobre Ciencia de Datos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Machine learning (DESARROLLO)\n",
        "\n"
      ],
      "metadata": {
        "id": "K-3j0GuhJvXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizar comparación de textos para encontrar la respuesta es bastante útil, pero utilizar un modelo entrenado de Machine Learning es mucho mejor, veamos como podemos entrenar el nuestro:\n",
        "\n",
        "Entre los mejores modelos para clasificación de texto, esto es, recibe una frase de entrada y devuelve el tipo de esta frase, tenemos los siguientes:\n",
        "\n",
        "**Naive Bayes (Básico)**\n",
        "\n",
        "**Random Forest (Intermedio)**\n",
        "\n",
        "**Transformers (Avanzado)**\n",
        "\n",
        "Usaremos el modelo Transformers que previamente fue entrenado de acuerdo a nuestro DataFrame\n",
        "\n",
        "Por último, en la función clasificacion_modelo()deberás usar tu modelo entrenado para predecir la frase ingresada por el usuario, una vez identificado el tipo de la frase, el algoritmo buscará la pregunta más parecida de este tipo en nuestro df_dialogo y devolverá su respectiva respuesta, en caso el tipo sea diferente de ‘Otros’ y su similaridad mayor a 0.5, sino devolverá en blanco."
      ],
      "metadata": {
        "id": "3YocAMhiKhnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL directa del archivo ZIP en GitHub\n",
        "zip_url = \"https://github.com/JorgeHdzRiv/Desafios_Alura_DS/raw/refs/heads/main/ChatBot/models/modelo.zip\"\n",
        "\n",
        "# Descargar el archivo ZIP\n",
        "os.system(f\"wget {zip_url} -O modelo.zip\")\n",
        "\n",
        "# Descomprimir la carpeta\n",
        "os.system(\"unzip -o modelo.zip\")\n",
        "\n",
        "# Eliminar el archivo ZIP después de extraer\n",
        "os.system(\"rm modelo.zip\")\n",
        "\n",
        "# Verificar archivos descargados\n",
        "os.system(\"ls ./modelo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_g3hlzfKlF1",
        "outputId": "068ae764-59b6-4e4a-cd1a-083f373dc4c0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo entrenado y el tokenizer\n",
        "ruta_modelo = './modelo'\n",
        "Modelo_TF = BertForSequenceClassification.from_pretrained(ruta_modelo)\n",
        "tokenizer_TF = BertTokenizer.from_pretrained(ruta_modelo)\n",
        "\n",
        "# Diccionario de clases (asegúrate de que esté correctamente alineado con tu modelo)\n",
        "diccionario = {0: 'Agradecimiento', 1: 'Aprendizaje', 2: 'Contacto', 3: 'Continuacion',\n",
        "               4: 'Despedida', 5: 'Edad', 6: 'Error', 7: 'Funcion', 8: 'Identidad',\n",
        "               9: 'Nombre', 10: 'Origen', 11: 'Otros', 12: 'Saludos', 13: 'Sentimiento',\n",
        "               14: 'Usuario'}\n",
        "\n",
        "# Función para procesar y clasificar la pregunta\n",
        "def clasificacion_modelo(pregunta):\n",
        "    frase = ' '.join(normalizar(pregunta))\n",
        "\n",
        "    # Tokenizar la frase de entrada\n",
        "    tokens = tokenizer_TF.encode_plus(\n",
        "        frase,\n",
        "        add_special_tokens=True,\n",
        "        max_length=128,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    # Obtener los input_ids y attention_mask\n",
        "    input_ids = tokens['input_ids']\n",
        "    attention_mask = tokens['attention_mask']\n",
        "\n",
        "    # Realizar la predicción\n",
        "    with torch.no_grad():\n",
        "        outputs = Modelo_TF(input_ids, attention_mask)\n",
        "\n",
        "    # Obtener las etiquetas predichas\n",
        "    etiquetas_predichas = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "    # Decodificar las etiquetas predichas\n",
        "    etiquetas_decodificadas = etiquetas_predichas.tolist()\n",
        "\n",
        "    # Obtener la clase encontrada\n",
        "    llave_buscada = etiquetas_decodificadas[0]\n",
        "    clase_encontrada = diccionario[llave_buscada]\n",
        "    print(\"Respuesta encontrada por el modelo Transformers\", \"se clasifica como: \", clase_encontrada)\n",
        "\n",
        "    # Buscar la respuesta más parecida si no es 'Otros'\n",
        "    if clase_encontrada != 'Otros':\n",
        "        # Buscar respuesta más parecida en la clase encontrada\n",
        "        df = df_dialogo[df_dialogo['tipo'] == clase_encontrada]\n",
        "        df.reset_index(inplace=True)\n",
        "\n",
        "        # Vectorización del texto\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        dialogos_num = vectorizer.fit_transform(df['dialogo'])\n",
        "        pregunta_num = vectorizer.transform([tratamiento_texto(pregunta)])\n",
        "\n",
        "        # Calcular la similaridad\n",
        "        similarity_scores = cosine_similarity(dialogos_num, pregunta_num)\n",
        "        indice_pregunta_proxima = similarity_scores.argmax()\n",
        "\n",
        "        # Si la similaridad es mayor a 0.5, devolver la respuesta\n",
        "        if max(similarity_scores) > 0.5:\n",
        "            respuesta = df['respuesta'][indice_pregunta_proxima]\n",
        "        else:\n",
        "            respuesta = ''\n",
        "            print('No se encontró una respuesta suficiente')\n",
        "\n",
        "    else:\n",
        "        respuesta = ''\n",
        "        print('La clase es \"Otros\", por lo que no se devuelve respuesta.')\n",
        "\n",
        "    return respuesta\n"
      ],
      "metadata": {
        "id": "6BaWIFcKOQE0"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Respuesta final del Chatbot"
      ],
      "metadata": {
        "id": "-ie4_oaPLvNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la función respuesta_chatbot(pregunta) nuestro algoritmo buscará primero la respuesta por comparación de textos y sino la encuentra la buscará por el modelo entrenado de Machine Learning, ya está todo listo, veamos en el próximo paso como ejecutar nuestro Chatbot."
      ],
      "metadata": {
        "id": "vo43XtNALpLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Función para devolver una respuesta final buscada en todos los métodos disponibles\n",
        "def respuesta_chatbot(pregunta):\n",
        "  respuesta = dialogo(pregunta)\n",
        "  if respuesta != '':\n",
        "    return respuesta\n",
        "  else:\n",
        "    respuesta = clasificacion_modelo(pregunta)\n",
        "    if respuesta != '':\n",
        "      return respuesta\n",
        "    else:\n",
        "      return 'Respuesta no encontrada'"
      ],
      "metadata": {
        "id": "r-F1HneVJ0Qf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.Ejecutar Chatbot"
      ],
      "metadata": {
        "id": "ocsqjWRBTtpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este último paso sólo tenemos que relajarnos y dialogar con nuestro Chatbot, hazle preguntas que estén en los documentos de diálogo, varia un poco tus preguntas, pregunta cosas que el Chatbot no haya visto durante su entrenamiento, pruébalo y observa como nos responde, estamos creando una Inteligencia Artificial, pongamos a prueba esa inteligencia."
      ],
      "metadata": {
        "id": "MwpYZorwTxQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = 'hola como estas mi hermano'\n",
        "respuesta = respuesta_chatbot(pregunta)\n",
        "print(respuesta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBHqWkboUcEY",
        "outputId": "8a0dc1e3-b62f-4ecd-f221-aa00b1b918eb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Respuesta encontrada por el modelo Transformers se clasifica como:  Saludos\n",
            "Estoy bien, gracias. ¿Y tú?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = 'Que es la inteligencia artificial'\n",
        "respuesta = respuesta_chatbot(pregunta)\n",
        "print(respuesta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY6PlOquQCRz",
        "outputId": "1b6fe168-4190-4d37-a732-2de2335b67cf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Respuesta encontrada por el método de comparación de textos - Probabilidad:  1.0\n",
            "La inteligencia artificial (IA) es un campo de la informática que se centra en crear sistemas informáticos inteligentes. Estos sistemas se diseñan para simular y replicar la capacidad de solución de problemas de los humanos. Esto se logra mediante el uso de algoritmos y técnicas especializadas para permitir que los sistemas informáticos sean capaces de reconocer patrones, comunicarse, aprender, razonar y tomar decisiones.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qLlbBW3uUbOh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}