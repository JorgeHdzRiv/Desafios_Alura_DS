{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9A2oSLDivrbN"
   },
   "source": [
    "# 1. Configurar ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UD0OObFGtZVJ"
   },
   "outputs": [],
   "source": [
    "#Instalando bibliotecas\n",
    "import pandas as pd\n",
    "import re, os, random, pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import jellyfish\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "#Definiendo variables del proyecto:\n",
    "nlp = spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQEIdACV2IE4"
   },
   "source": [
    "# 2. Importar verbos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8DDVG_F22IvU"
   },
   "outputs": [],
   "source": [
    "# Importar la lista_verbos:\n",
    "lista_verbos = 'tu algoritmo'\n",
    "\n",
    "# Importar el diccionario:\n",
    "verbos_irregulares = 'tu algoritmo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDRIGcy62JuE"
   },
   "source": [
    "# 3. Tratamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-__6F0I2MjG"
   },
   "outputs": [],
   "source": [
    "#Función para encontrar la raiz de las palabras\n",
    "def raiz(palabra):\n",
    "  palabra_encontrada = 'tu algoritmo'\n",
    "  return palabra_encontrada\n",
    "\n",
    "def tratamiento_texto(texto):\n",
    "  texto = 'tu algoritmo'\n",
    "  return texto\n",
    "\n",
    "#Función para reemplazar el final de una palabra por 'r'\n",
    "def reemplazar_terminacion(palabra):\n",
    "  nueva_palabra = 'tu algoritmo'\n",
    "  return nueva_palabra.split()[0]\n",
    "\n",
    "#Función para devolver los tokens normalizados del texto\n",
    "def normalizar(texto):\n",
    "  tokens=[]\n",
    "  doc = nlp(texto)\n",
    "  for t in doc:\n",
    "    lemma=verbos_irregulares.get(t.text, t.lemma_.split()[0])\n",
    "    lemma=re.sub(r'[^\\w\\s+\\-*/]', '', lemma)\n",
    "    if t.pos_ in ('VERB','PROPN','PRON','NOUN','AUX','SCONJ','ADJ','ADV','NUM') or lemma in lista_verbos:\n",
    "      if t.pos_=='VERB':\n",
    "        lemma = reemplazar_terminacion(lemma)\n",
    "        tokens.append(raiz(tratamiento_texto(lemma)))\n",
    "      else:\n",
    "        tokens.append(tratamiento_texto(lemma))\n",
    "\n",
    "  tokens = list(dict.fromkeys(tokens))\n",
    "  tokens = list(filter(None, tokens))\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RnqKO9ChOpY"
   },
   "source": [
    "# 4. Cargar bases de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1894SyvPhQJ0"
   },
   "outputs": [],
   "source": [
    "#Importando bases de dialogo fluído\n",
    "txt_folder_path = folder+'/dialogos'\n",
    "lista_documentos=[x for x in os.listdir(txt_folder_path) if x.endswith(\".txt\")]\n",
    "lista_dialogos, lista_dialogos_respuesta, lista_tipo_dialogo = [],[],[]\n",
    "for idx in range(len(lista_documentos)):\n",
    "  f=open(txt_folder_path+'/'+lista_documentos[idx], 'r', encoding='utf-8', errors='ignore')\n",
    "  for line in f.read().split('\\n'):\n",
    "    lista_dialogos = 'Tu algoritmo aqui'\n",
    "    lista_tipo_dialogo = 'Tu algoritmo aqui'\n",
    "    lista_dialogos_respuesta = 'Tu algoritmo aqui'\n",
    "\n",
    "#Creando Dataframe de diálogos\n",
    "datos = {'dialogo':lista_dialogos,'respuesta':lista_dialogos_respuesta,'tipo':lista_tipo_dialogo,'interseccion':0,'jaro_winkler':0,'probabilidad':0}\n",
    "df_dialogo = pd.DataFrame(datos)\n",
    "df_dialogo = df_dialogo.drop_duplicates(keep='first')\n",
    "df_dialogo.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVJ6UmQV3n4T"
   },
   "source": [
    "# 5. Buscar respuesta del Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bpxajyck3pav"
   },
   "outputs": [],
   "source": [
    "#Función para verificar si el usuário inició un diálogo\n",
    "def dialogo(user_response):\n",
    "  user_response = tratamiento_texto(user_response) #Tratando el texto\n",
    "  user_response = re.sub(r\"[^\\w\\s]\", '', user_response) #Elimina signos de puntuación\n",
    "  df = df_dialogo.copy()\n",
    "  for idx,row in df.iterrows():\n",
    "    df.at[idx,'interseccion'] = \"tu algoritmo aqui metodo1(user_response, row['dialogo'])\"\n",
    "    df.at[idx,'similarity'] = \"tu algoritmo aqui metodo2(user_response, row['dialogo'])\"\n",
    "    df.at[idx,'jaro_winkler'] = \"tu algoritmo aqui metodo3(user_response, row['dialogo'])\"\n",
    "    df.at[idx,'probabilidad'] = max(df.at[idx,'interseccion'],df.at[idx,'similarity'],df.at[idx,'jaro_winkler'])\n",
    "  df.sort_values(by=['probabilidad','jaro_winkler'], inplace=True, ascending=False)\n",
    "  probabilidad = df['probabilidad'].head(1).values[0]\n",
    "  if probabilidad >= 0.93:\n",
    "    print('Respuesta encontrada por el método de comparación de textos - Probabilidad: ', probabilidad)\n",
    "    respuesta = df['respuesta'].head(1).values[0]\n",
    "  else:\n",
    "    respuesta = ''\n",
    "  return respuesta\n",
    "\n",
    "#Cargar tu modelo entrenado aqui(recuerda siempre cargar el modelo y el vectorizer o tokenizer usado en el entrenamiento del modelo):\n",
    "ruta_modelo = folder+'/modelo'\n",
    "Modelo_TF = BertForSequenceClassification.from_pretrained(ruta_modelo)\n",
    "tokenizer_TF = BertTokenizer.from_pretrained(ruta_modelo)\n",
    "\n",
    "#Función para dialogar utilizando el modelo\n",
    "def clasificacion_modelo(pregunta):\n",
    "  frase = ' '.join(normalizar(pregunta))\n",
    "  clase_encontrada = 'Realiza la predicción de la frase con tu modelo aqui'\n",
    "\n",
    "  #Buscar respuesta más parecida en la clase encontrada\n",
    "  df = df_dialogo[df_dialogo['tipo'] == clase_encontrada]\n",
    "  df.reset_index(inplace=True)\n",
    "  vectorizer = TfidfVectorizer()\n",
    "  dialogos_num = vectorizer.fit_transform(df['dialogo'])\n",
    "  pregunta_num = vectorizer.transform([tratamiento_texto(pregunta)])\n",
    "  similarity_scores = cosine_similarity(dialogos_num, pregunta_num)\n",
    "  indice_pregunta_proxima = similarity_scores.argmax()\n",
    "\n",
    "  if max(similarity_scores)>0.5 and clase_encontrada not in ['Otros']:\n",
    "    print('Respuesta encontrada por el modelo Transformers - tipo:',clase_encontrada)\n",
    "    respuesta = df['respuesta'][indice_pregunta_proxima]\n",
    "  else:\n",
    "    respuesta = ''\n",
    "  return respuesta\n",
    "\n",
    "#Función para devolver una respuesta final buscada en todos los métodos disponibles\n",
    "def respuesta_chatbot(pregunta):\n",
    "  respuesta = dialogo(pregunta)\n",
    "  if respuesta != '':\n",
    "    return respuesta\n",
    "  else:\n",
    "    respuesta = clasificacion_modelo(pregunta)\n",
    "    if respuesta != '':\n",
    "      return respuesta\n",
    "    else:\n",
    "      return 'Respuesta no encontrada'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMEwexpz4gdI"
   },
   "source": [
    "# 6. Ejecutar Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2380,
     "status": "ok",
     "timestamp": 1686517495545,
     "user": {
      "displayName": "Alejandro Gamarra (ElProfeAlejo)",
      "userId": "00472658790543316179"
     },
     "user_tz": 180
    },
    "id": "X_wq8HMP4hmU",
    "outputId": "e1932f0a-bea4-4d91-df2e-bc04081c839e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta encontrada por el modelo Transformers - tipo: Saludos\n",
      "Estoy bien, gracias. ¿Y tú?\n"
     ]
    }
   ],
   "source": [
    "pregunta='CÓMO ESTAS'\n",
    "respuesta = respuesta_chatbot(pregunta)\n",
    "print(respuesta)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "qQEIdACV2IE4",
    "kDRIGcy62JuE",
    "_RnqKO9ChOpY",
    "IVJ6UmQV3n4T"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
